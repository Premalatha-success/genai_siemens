{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "id": "9xOfg3-rylvi",
        "outputId": "d60df2f2-2439-4252-bb23-9a789b5ff3ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://20c61d025f1d466f23.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://20c61d025f1d466f23.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "import gradio as gr\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "# Load pre-trained GPT-2 model and tokenizer\n",
        "model_name = \"gpt2\"\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "\n",
        "# Define Gradio interface components\n",
        "prompt_input = gr.Textbox(lines=5, label=\"Enter your prompt\")\n",
        "max_length_input = gr.Number(label=\"Max length of generated text\")\n",
        "\n",
        "# Generate text function\n",
        "def generate_text(prompt, max_length=50):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\", max_length=max_length, truncation=True)\n",
        "    outputs = model.generate(**inputs, max_length=50, num_return_sequences=1)\n",
        "    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return generated_text\n",
        "\n",
        "# Create Gradio interface\n",
        "gr.Interface(\n",
        "    fn=generate_text,\n",
        "    inputs=[prompt_input, max_length_input],\n",
        "    outputs=gr.Textbox(label=\"Generated Text\"),\n",
        "    title=\"GPT-2 Text Generation\",\n",
        "    description=\"Generate text based on a prompt using GPT-2.\",\n",
        ").launch()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
        "\n",
        "# Load pre-trained GPT-2 model and tokenizer\n",
        "model_name = \"gpt2\"\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "\n",
        "# Define Gradio interface component\n",
        "chat_input = gr.Textbox(lines=5, label=\"You:\")\n",
        "chat_output = gr.Textbox(lines=5, label=\"Bot:\")\n",
        "\n",
        "# Define function for generating bot response\n",
        "def generate_response(chat_text):\n",
        "    # Tokenize input text\n",
        "    input_ids = tokenizer.encode(chat_text, return_tensors=\"pt\")\n",
        "\n",
        "    # Generate response\n",
        "    max_length = len(input_ids[0]) + 50  # adjust max_length based on input length\n",
        "    output = model.generate(input_ids, max_length=max_length, num_return_sequences=1)\n",
        "\n",
        "    # Decode response and return\n",
        "    response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    return response\n",
        "\n",
        "# Create Gradio interface\n",
        "gr.Interface(\n",
        "    fn=generate_response,\n",
        "    inputs=chat_input,\n",
        "    outputs=chat_output,\n",
        "    title=\"GPT-2 Chatbot\",\n",
        "    description=\"Enter a message to chat with the bot.\",\n",
        ").launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "id": "VbUNnf880aw_",
        "outputId": "2d7be245-63f7-48f8-b970-e1c5960da15e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://00e454cf6975ee1cce.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://00e454cf6975ee1cce.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0S5cYwR-y08h"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}